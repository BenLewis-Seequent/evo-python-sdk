from __future__ import annotations

import copy
import sys
import weakref
from dataclasses import dataclass
from typing import Any, ClassVar

import pandas as pd

from evo import jmespath
from evo.common import IFeedback
from evo.common.utils import NoFeedback
from evo.objects import DownloadedObject, ObjectMetadata, ObjectReference, ObjectSchema, SchemaVersion

from .adapters import AttributesAdapter, DatasetAdapter, ValuesAdapter
from .evo_context import EvoContext
from .store import Dataset
from .types import BoundingBox, EpsgCode

if sys.version_info >= (3, 11):
    from typing import Self
else:
    from typing_extensions import Self

__all__ = ["BaseObject", "BaseSpatialObject", "SingleDatasetObject"]


@dataclass(kw_only=True)
class BaseObjectData:
    name: str
    description: str | None = None
    tags: dict[str, str] | None = None
    extensions: dict[str, Any] | None = None


class BaseObject:
    """Base class for all Geoscience Objects."""

    _sub_classification_lookup: ClassVar[weakref.WeakValueDictionary[str, type[BaseObject]]] = (
        weakref.WeakValueDictionary()
    )

    sub_classification: ClassVar[str | None] = None
    """The sub-classification of the Geoscience Object schema.
    
    If None, this class is considered abstract and cannot be instantiated directly.
    """

    creation_schema_version: ClassVar[SchemaVersion | None] = None
    """The version of the Geoscience Object schema to use when creating new objects of this type.
    
    If None, this class can't create a new Geoscience Object, but can still load an existing one.
    """

    def __init__(self, evo_context: EvoContext, obj: DownloadedObject) -> None:
        """
        :param evo_context: The context containing the environment, connector, and cache to use.
        :param obj: The DownloadedObject representing the Geoscience Object.
        """
        evo_context.check_object_reference(obj.metadata.url)
        self._evo_context = evo_context
        self._obj = obj
        self._document = obj.as_dict()

    @classmethod
    def _construct_from_object(cls, evo_context: EvoContext, obj: DownloadedObject) -> Self:
        return cls(evo_context, obj)

    @classmethod
    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__()
        if cls.sub_classification is not None:
            existing_cls = cls._sub_classification_lookup.get(cls.sub_classification)
            if existing_cls is not None:
                raise ValueError(
                    f"Duplicate sub_classification '{cls.sub_classification}' for {cls.__name__}; "
                    f"already registered by {existing_cls.__name__}"
                )
            cls._sub_classification_lookup[cls.sub_classification] = cls

    @classmethod
    async def _data_to_dict(cls, data: BaseObjectData, evo_context: EvoContext) -> dict[str, Any]:
        """Convert the provided data to a dictionary suitable for creating a Geoscience Object.

        :param data: The BaseObjectData to convert.
        :param evo_context: The context used to upload any data required for the object.
        :return: The dictionary representation of the data.
        """

        if cls.sub_classification is None or cls.creation_schema_version is None:
            raise NotImplementedError(
                f"Class '{cls.__name__}' cannot create new objects; "
                "sub_classification and creation_schema_version must be defined by the subclass"
            )
        result: dict[str, Any] = {
            "schema": str(ObjectSchema("objects", cls.sub_classification, cls.creation_schema_version)),
            "name": data.name,
        }
        if data.description is not None:
            result["description"] = data.description
        if data.tags is not None:
            result["tags"] = data.tags
        if data.extensions is not None:
            result["extensions"] = data.extensions
        return result

    @classmethod
    async def _create(
        cls,
        evo_context: EvoContext,
        data: BaseObjectData,
        parent: str | None = None,
    ) -> Self:
        """Create a new object.

        :param evo_context: The context containing the environment, connector, and cache to use.
        :param data: The data that will be used to create the object.
        :param parent: Optional parent path for the object.
        """

        object_dict = await cls._data_to_dict(data, evo_context)
        object_dict["uuid"] = None  # New UUID is generated by the service
        if parent is not None:
            evo_context = evo_context.with_folder(parent)
        obj = await evo_context.create_geoscience_object(object_dict)
        return cls._construct_from_object(evo_context, obj)

    @classmethod
    async def _replace(
        cls,
        evo_context: EvoContext,
        reference: str,
        data: BaseObjectData,
    ) -> Self:
        """Replace an existing object.

        :param evo_context: The context containing the environment, connector, and cache to use.
        :param reference: The reference of the object to replace.
        :param data: The data that will be used to create the object.
        """
        reference = ObjectReference(reference)
        evo_context = evo_context.with_workspace(
            workspace=reference.workspace_id,
            org_id=reference.org_id,
            hub_url=reference.hub_url,
        )
        object_dict = await cls._data_to_dict(data, evo_context)
        obj = await evo_context.replace_geoscience_object(reference, object_dict)
        return cls._construct_from_object(evo_context, obj)

    @classmethod
    def _adapt(cls, evo_context: EvoContext, obj: DownloadedObject) -> Self:
        selected_cls = cls._sub_classification_lookup.get(obj.metadata.schema_id.sub_classification)
        if selected_cls is None:
            raise ValueError(f"No class found for sub-classification '{obj.metadata.schema_id.sub_classification}'")

        if not issubclass(selected_cls, cls):
            raise ValueError(
                f"Referenced object with sub-classification '{obj.metadata.schema_id.sub_classification}' "
                f"cannot be adapted to '{cls.__name__}'"
            )
        return selected_cls._construct_from_object(evo_context, obj)

    @classmethod
    async def from_reference(
        cls,
        evo_context: EvoContext,
        reference: ObjectReference | str,
    ) -> Self:
        """Download a GeoscienceObject from the given reference, adapting it to this GeoscienceObject type.

        :param evo_context: The context for connecting to Evo APIs.
        :param reference: The ObjectReference (or its string ID) identifying the object to download.

        :return: A GeoscienceObject instance.

        :raises ValueError: If the referenced object cannot be adapted to this GeoscienceObject type.
        """
        reference = ObjectReference(reference)
        evo_context = evo_context.with_workspace(
            workspace=reference.workspace_id,
            org_id=reference.org_id,
            hub_url=reference.hub_url,
        )
        obj = await evo_context.download_geoscience_object(reference)
        return cls._adapt(evo_context, obj)

    @property
    def metadata(self) -> ObjectMetadata:
        """The metadata of the Geoscience Object.

        This does not include any local changes since the object was last updated.
        """
        return self._obj.metadata

    def as_dict(self) -> dict[str, Any]:
        """Get the Geoscience Object as a dictionary.

        :return: The Geoscience Object as a dictionary.
        """
        return copy.deepcopy(self._document)

    @property
    def name(self) -> str:
        """The name of the Geoscience Object."""
        if not isinstance(name := self._document.get("name"), str):
            raise ValueError("Object does not contain a valid 'name' field")
        else:
            return name

    @name.setter
    def name(self, name: str) -> None:
        """Set the name of the Geoscience Object."""
        if not isinstance(name, str):
            raise ValueError("Name must be a string")
        self._document["name"] = name

    @property
    def description(self) -> str | None:
        """The description of the Geoscience Object, if defined."""
        description = self._document.get("description")
        if description is None or isinstance(description, str):
            return description
        else:
            raise ValueError("Object does not contain a valid 'description' field")

    @description.setter
    def description(self, description: str | None) -> None:
        """Set the description of the Geoscience Object."""
        if description is not None and not isinstance(description, str):
            raise ValueError("Description must be a string or None")
        if description is None:
            if "description" in self._document:
                del self._document["description"]
        else:
            self._document["description"] = description

    @property
    def tags(self) -> dict[str, str]:
        """The tags defined on the Geoscience Object, or an empty dict if no tags are defined."""
        tags = self._document.get("tags")
        if tags is None:
            return {}
        elif isinstance(tags, dict):
            return {str(k): str(v) for k, v in tags.items()}
        else:
            raise ValueError("Object does not contain a valid 'tags' field")

    @property
    def extensions(self) -> dict:
        """The extensions defined on the Geoscience Object, or an empty dict if no extensions are defined."""
        extensions = self._document.get("extensions")
        if extensions is None:
            return {}
        elif isinstance(extensions, dict):
            return extensions
        else:
            raise ValueError("Object does not contain a valid 'extensions' field")

    def search(self, expression: str) -> Any:
        """Search the object metadata using a JMESPath expression.

        :param expression: The JMESPath expression to use for the search.

        :return: The result of the search.
        """
        return jmespath.search(expression, self._document)

    async def update(self):
        """Update the object on the geoscience object service"""
        self._obj = await self._obj.update(self._document)


@dataclass(kw_only=True)
class BaseSpatialObjectData(BaseObjectData):
    # The bounding box cam be automatically derived from the data, but can also be provided explicitly
    bounding_box: BoundingBox | None = None
    coordinate_reference_system: EpsgCode | str | None = None

    def get_bounding_box(self) -> BoundingBox:
        """Get the bounding box for the object data.

        If the bounding box is not explicitly provided, it will be derived from the data.

        :return: The bounding box for the object data.

        :raises ValueError: If the bounding box cannot be derived from the data.
        """
        if self.bounding_box is not None:
            return self.bounding_box
        else:
            raise ValueError("Bounding box must be provided explicitly in BaseSpatialObjectData")


class BaseSpatialObject(BaseObject):
    """Base class for all Geoscience Objects with spatial data."""

    @classmethod
    async def _data_to_dict(cls, data: BaseSpatialObjectData, evo_context: EvoContext) -> dict[str, Any]:
        """Create a object dictionary suitable for creating a new Geoscience Object."""
        object_dict = await super()._data_to_dict(data, evo_context)
        if data.coordinate_reference_system is None:
            object_dict["coordinate_reference_system"] = "unspecified"
        if isinstance(data.coordinate_reference_system, EpsgCode):
            object_dict["coordinate_reference_system"] = {"epsg_code": data.coordinate_reference_system}
        elif isinstance(data.coordinate_reference_system, str):
            object_dict["coordinate_reference_system"] = {"ogc_wkt": data.coordinate_reference_system}
        else:
            raise ValueError("coordinate_reference_system must be an EpsgCode, str, or None")

        object_dict["bounding_box"] = data.get_bounding_box().to_dict()
        return object_dict

    @property
    def coordinate_reference_system(self) -> EpsgCode | str | None:
        search_result = self.search("coordinate_reference_system | epsg_code || ogc_wkt || @")
        if search_result == "unspecified":
            return None
        elif isinstance(search_result, int):
            return EpsgCode(search_result)
        elif isinstance(search_result, str):
            return search_result
        else:
            raise ValueError("Object does not contain a valid 'coordinate_reference_system' field")

    @property
    def bounding_box(self) -> BoundingBox:
        """Get the bounding box of the Geoscience Object, if defined.

        :return: The bounding box dict as a JMESPathObjectProxy, or None if no bounding box is defined.

        :raises ValueError: If the bounding box field is present but does not contain a valid bounding box dict.
        """
        bounding_box = self._document.get("bounding_box")
        if isinstance(bounding_box, dict):
            return BoundingBox.from_dict(bounding_box)
        else:
            raise ValueError("Object does not contain a valid 'bounding_box' field")

    @bounding_box.setter
    def bounding_box(self, bounding_box: BoundingBox) -> None:
        """Set the bounding box of the Geoscience Object.

        :param bounding_box: The bounding box to set.
        """
        self._document["bounding_box"] = bounding_box.to_dict()


@dataclass(kw_only=True)
class SingleDatasetObjectData(BaseSpatialObjectData):
    data: pd.DataFrame


class SingleDatasetObject(BaseSpatialObject):
    """A Geoscience Object that can be represented in a single DataFrame."""

    attributes_adapters: ClassVar[list[AttributesAdapter]] = []
    """List of attribute adapters available for this object type.
    
    Only one adapter per major version should be listed.
    """
    value_adapters: ClassVar[list[ValuesAdapter]] = []
    """List of value adapters available for this object type."""

    @classmethod
    def _get_dataset_adapter(cls, schema_id: ObjectSchema) -> DatasetAdapter:
        return DatasetAdapter.from_adapter_lists(
            schema_id.version.major,
            cls.value_adapters,
            cls.attributes_adapters,
        )

    def __init__(self, evo_context: EvoContext, obj: DownloadedObject, dataset_adapter: DatasetAdapter) -> None:
        """
        :param obj: The DownloadedObject representing the Geoscience Object.
        :param dataset_adapter: The DatasetAdapter for the Geoscience Object.
        """
        super().__init__(evo_context, obj)
        self._dataset_adapter = dataset_adapter
        self._reset_from_object()

    @classmethod
    def _construct_from_object(cls, evo_context: EvoContext, obj: DownloadedObject) -> Self:
        if obj.metadata.schema_id.sub_classification != cls.sub_classification:
            raise ValueError(f"Cannot adapt '{obj.metadata.schema_id.classification}' to {cls.__name__}")

        adapter = cls._get_dataset_adapter(obj.metadata.schema_id)
        return cls(evo_context, obj, adapter)

    @classmethod
    async def _data_to_dict(cls, data: SingleDatasetObjectData, evo_context: EvoContext) -> dict[str, Any]:
        object_dict = await super()._data_to_dict(data, evo_context)

        # Populate the object with the provided data
        dataset = Dataset(
            document=object_dict,
            dataset_adapter=cls._get_dataset_adapter(ObjectSchema.from_id(object_dict["schema"])),
            evo_context=evo_context,
        )
        await dataset.set_dataframe(data.data)
        # Ensure the object_dict is updated with any changes made during set_dataframe
        dataset.update_document()

        return object_dict

    def _reset_from_object(self) -> None:
        self._dataset = Dataset(
            document=self._document, dataset_adapter=self._dataset_adapter, obj=self._obj, evo_context=self._evo_context
        )

    def as_dict(self) -> dict[str, Any]:
        """Get the Geoscience Object as a dictionary.

        :return: The Geoscience Object as a dictionary.
        """
        self._dataset.update_document()
        return super().as_dict()

    @property
    def values(self):
        return self._dataset.values

    @property
    def attributes(self):
        return self._dataset.attributes

    async def as_dataframe(self, *keys: str, fb: IFeedback = NoFeedback) -> pd.DataFrame:
        """Load a DataFrame containing the object's base values and the values from the specified attributes.

        :param keys: Optional list of attribute keys to filter the attributes by. If no keys are provided, all
            attributes will be loaded.
        :param fb: Optional feedback object to report download progress.

        :return: The loaded DataFrame with values from all sources and the specified attributes, applying lookup tables
            and NaN values as specified. The column name(s) will be updated to match the column names provided in the
            ValuesAdapters and the attribute names.
        """
        return await self._dataset.as_dataframe(*keys, fb=fb)

    async def set_dataframe(self, df: pd.DataFrame, fb: IFeedback = NoFeedback) -> None:
        """Set the object's data from the provided DataFrame.

        Any attributes that are not present in the DataFrame but exist on the object, will be deleted.

        :param df: The DataFrame containing the data to set on the object.
        :param fb: Optional feedback object to report progress.
        """
        return await self._dataset.set_dataframe(df, fb)

    async def update_attributes(self, df: pd.DataFrame, fb: IFeedback = NoFeedback) -> None:
        """Update or create attributes on the object from the provided DataFrame.

        Any attributes that are not present in the DataFrame but exist on the object, will remain unchanged.

        The non-attribute data in the DataFrame will be ignored.

        :param df: The DataFrame containing the attribute data to set on the object.
        :param fb: Optional feedback object to report progress.
        """
        return await self._dataset.update_attributes(df, fb)

    async def update(self):
        """Update the object on the Geoscience Object Service.

        If the object has yet to be created on the service, it will be created instead.
        """
        self.attributes.update_document()
        await super().update()
        self._reset_from_object()


class ChildDataset:
    def __init__(self, value_adapters: list[ValuesAdapter], attributes_adapters: list[AttributesAdapter]) -> None:
        self.value_adapters = value_adapters
        self.attributes_adapters = attributes_adapters
        self.name = None

    def __set_name__(self, owner: type[MultiDatasetObject], name: str):
        self.name = name

    def __get__(self, instance: MultiDatasetObject, owner: type[MultiDatasetObject]) -> Dataset | ChildDataset:
        if instance is None:
            return self
        if self.name is None:
            raise ValueError("ChildDataset name not set")
        return instance.get_dataset_by_name(self.name)


class MultiDatasetObject(BaseSpatialObject):
    datasets: ClassVar[list[ChildDataset]] = []
    """List of datasets available for this object type."""

    @classmethod
    def _get_dataset_adapters(cls, schema_id: ObjectSchema) -> dict[str, DatasetAdapter]:
        return {
            dataset_spec.name: DatasetAdapter.from_adapter_lists(
                schema_id.version.major,
                dataset_spec.value_adapters,
                dataset_spec.attributes_adapters,
            )
            for dataset_spec in cls.datasets
        }

    @classmethod
    async def _set_data(
        cls, object_dict: dict[str, Any], evo_context: EvoContext, dataset_spec: ChildDataset, data: pd.DataFrame
    ) -> None:
        # Populate the object with the provided data
        dataset_adapters = cls._get_dataset_adapters(ObjectSchema.from_id(object_dict["schema"]))
        dataset_adapter = dataset_adapters[dataset_spec.name]
        dataset = Dataset(document=object_dict, dataset_adapter=dataset_adapter, evo_context=evo_context)
        await dataset.set_dataframe(data)
        # Ensure the object_dict is updated with any changes made during set_dataframe
        dataset.update_document()

    def __init__(
        self, evo_context: EvoContext, obj: DownloadedObject, dataset_adapters: dict[str, DatasetAdapter]
    ) -> None:
        """
        :param obj: The DownloadedObject representing the Geoscience Object.
        :param dataset_adapters: Set of DatasetAdapters for the Geoscience Object.
        """
        super().__init__(evo_context, obj)
        self._dataset_adapters = dataset_adapters
        self._reset_from_object()

    @classmethod
    def _construct_from_object(cls, evo_context: EvoContext, obj: DownloadedObject) -> Self:
        if obj.metadata.schema_id.sub_classification != cls.sub_classification:
            raise ValueError(f"Cannot adapt '{obj.metadata.schema_id.classification}' to {cls.__name__}")

        adapters = cls._get_dataset_adapters(obj.metadata.schema_id)
        return cls(evo_context, obj, adapters)

    def _reset_from_object(self) -> None:
        self._datasets = {
            key: Dataset(
                document=self._document,
                dataset_adapter=adapter,
                obj=self._obj,
                evo_context=self._evo_context,
            )
            for key, adapter in self._dataset_adapters.items()
        }

    def get_dataset_by_name(self, name: str) -> Dataset:
        """Get the dataset by its name.

        :param name: The name of the dataset.

        :return: The Dataset instance.

        :raises KeyError: If the dataset with the specified name does not exist.
        """
        return self._datasets[name]

    def as_dict(self) -> dict[str, Any]:
        """Get the Geoscience Object as a dictionary.

        :return: The Geoscience Object as a dictionary.
        """
        for dataset in self._datasets.values():
            dataset.update_document()
        return super().as_dict()

    async def update(self):
        """Update the object on the Geoscience Object Service.

        If the object has yet to be created on the service, it will be created instead.
        """
        for dataset in self._datasets.values():
            dataset.update_document()
        await super().update()
        self._reset_from_object()
